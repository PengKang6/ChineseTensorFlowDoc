{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TnJztDZGw-n"
   },
   "source": [
    "# 使用RNN文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUWearf0Gw-p"
   },
   "source": [
    "这部分将在IMDB评论集上训练一个RNN情感分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2VQo4bajwUU"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z682XYsrjkY9"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rXHa-w9JZhb"
   },
   "source": [
    "导入 `matplotlib`，定义一个画图函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mp1Z7P9pYRSK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "## 设置输入管道\n",
    "\n",
    "\n",
    "IMDB电影评论数据集是一个二元分类数据集，所有评论要么是正面的，要么是负面的。\n",
    "\n",
    "使用[TFDS]下载数据集.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHRwRoP2nVHX"
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_examples, test_examples = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCorLciXSDJE"
   },
   "source": [
    " 数据集的 `info`包含编码器 (`tfds.features.text.SubwordTextEncoder`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EplYp5pNnW1S"
   },
   "outputs": [],
   "source": [
    "encoder = info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7ACuHM5hFp3"
   },
   "outputs": [],
   "source": [
    "print('Vocabulary size: {}'.format(encoder.vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAfGg8YRe6fu"
   },
   "source": [
    "文本编码器对字符串进行编码和解码，如果必要将使用字节编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bq6xDmf2SAs-"
   },
   "outputs": [],
   "source": [
    "sample_string = 'Hello TensorFlow.'\n",
    "\n",
    "encoded_string = encoder.encode(sample_string)\n",
    "print('Encoded string is {}'.format(encoded_string))\n",
    "\n",
    "original_string = encoder.decode(encoded_string)\n",
    "print('The original string: \"{}\"'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TN7QbKaM4-5H"
   },
   "outputs": [],
   "source": [
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDVc6UGO5Dh6"
   },
   "outputs": [],
   "source": [
    "for index in encoded_string:\n",
    "  print('{} ----> {}'.format(index, encoder.decode([index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlYWqhTVlUyQ"
   },
   "source": [
    "## 准备训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2qVJzcEluH_"
   },
   "source": [
    "接下来创建编码字符串的批。使用 `padded_batch`方法0填充序列到批中最长长度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDsCaZCDYZgm"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VznrltNOnUc5"
   },
   "outputs": [],
   "source": [
    "train_dataset = (train_examples\n",
    "                 .shuffle(BUFFER_SIZE)\n",
    "                 .padded_batch(BATCH_SIZE, padded_shapes=([None],[])))\n",
    "\n",
    "test_dataset = (test_examples\n",
    "                .padded_batch(BATCH_SIZE,  padded_shapes=([None],[])))\n",
    "\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fMoMQlgViru"
   },
   "source": [
    "注意：在**TensorFlow 2.2** 参数padded_shapes不再需要，缺省行为就是将所有轴填充到批中最大长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rna67ewhViQ5"
   },
   "outputs": [],
   "source": [
    "train_dataset = (train_examples\n",
    "                 .shuffle(BUFFER_SIZE)\n",
    "                 .padded_batch(BATCH_SIZE))\n",
    "\n",
    "test_dataset = (test_examples\n",
    "                .padded_batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bjUqGVBxGw-t"
   },
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgs6nnSTGw-t"
   },
   "source": [
    "创建一个`tf.keras.Sequential`模型，嵌入层作为模型的第一层。嵌入层对每个词保存一个向量。当调用时，它将词索引序列转换成向量序列。这些嵌入向量是可学习的。训练后，具有相似意义的词将有相似的向量。\n",
    "\n",
    "这个索引查找比通过`tf.keras.layers.Dense`层传递单热向量要有效得多。\n",
    "\n",
    "循环神经网络RNN迭代的处理序列中的元素。RNN将一个时间步的输出作为下一时间步的输入，如此循环往复.\n",
    "\n",
    "`tf.keras.layers.Bidirectional`包装器和RNN一起使用，它使得RNN正向和反向处理序列，并将输出拼接concat起来，这可以帮助RNN学习长距离依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LwfoBkmRYcP3"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRI776ZcH3Tf"
   },
   "source": [
    "编译模型以配置训练过程:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kj2xei41YZjC"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIwH3nto596k"
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hw86wWS4YgR2"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BaNbXi43YgUT"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwSE_386uhxD"
   },
   "source": [
    "上面模型没有对序列的填充进行掩蔽。如果在填充序列上训练，在未填充序列上测试，这可能导致偏差。理想情况下，你可以使用掩蔽来避免这些，但是，这对结果的影响较小。\n",
    "\n",
    "如果预测>= 0.5, 评论是正面的，否则是负面的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8w0dseJMiEUh"
   },
   "outputs": [],
   "source": [
    "def pad_to_size(vec, size):\n",
    "  zeros = [0] * (size - len(vec))\n",
    "  vec.extend(zeros)\n",
    "  return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-E4cgkIvmVu"
   },
   "outputs": [],
   "source": [
    "def sample_predict(sample_pred_text, pad):\n",
    "  encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
    "\n",
    "  if pad:\n",
    "    encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
    "  encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "  predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
    "\n",
    "  return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O41gw3KfWHus"
   },
   "outputs": [],
   "source": [
    "# 在未填充文本上预测.\n",
    "\n",
    "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
    "                    'were out of this world. I would recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFh4xLARucTy"
   },
   "outputs": [],
   "source": [
    "# 在填充文本上预测\n",
    "\n",
    "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
    "                    'were out of this world. I would recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=True)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfIVoxiNmKBF"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUzgkqnhmKD2"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7g1evcaRpTKm"
   },
   "source": [
    "## 堆叠多个LSTM层\n",
    "\n",
    "Keras循环层通过`return_sequences`构造参数可以有两种不同的模式:\n",
    "\n",
    "* 返回每个时间步连续输出完整序列（一个3D张量，形状为`(batch_size, timesteps, output_features)`）.\n",
    "* 只返回输入序列最后的输出（一个2D张量，形状为`(batch_size, output_features)`）."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jo1jjO3vn0jo"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEPV5jVGp-is"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeSE-YjdqAeN"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LdwilM1qPM3"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykUKnAoqbycW"
   },
   "outputs": [],
   "source": [
    "# 在没有填充的文本上预测.\n",
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RiC-94zvdZO"
   },
   "outputs": [],
   "source": [
    "# 在填充文本上预测\n",
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=True)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YYub0EDtwCu"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPV3Nn9xtwFM"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xvpE3BaGw_V"
   },
   "source": [
    "以上例子可以使用其他的循环层，例如[GRU layers]， 你当然也可以对RNN进行定制，定制参考指南部分。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification_rnn.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
